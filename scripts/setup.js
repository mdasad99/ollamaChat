const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');

console.log('üöÄ Setting up Local ChatGPT with Ollama...\n');

const envPath = path.join(__dirname, '..', '.env.local');
if (!fs.existsSync(envPath)) {
  console.log('üìù Creating .env.local file...');
  const exampleEnv = fs.readFileSync(path.join(__dirname, '..', '.env.local.example'), 'utf8');
  fs.writeFileSync(envPath, exampleEnv);
  console.log('‚úÖ .env.local created. Please update with your database credentials.\n');
} else {
  console.log('‚úÖ .env.local already exists.\n');
}

try {
  execSync('ollama --version', { stdio: 'ignore' });
  console.log('‚úÖ Ollama is installed.');
} catch (error) {
  console.log('‚ùå Ollama is not installed. Please install from https://ollama.com/download');
  process.exit(1);
}

try {
  const models = execSync('ollama list', { encoding: 'utf8' });
  if (models.includes('gemma3:1b')) {
    console.log('‚úÖ gemma3:1b model is available.');
  } else {
    console.log('üì¶ Pulling gemma3:1b model...');
    execSync('ollama pull gemma3:1b', { stdio: 'inherit' });
    console.log('‚úÖ gemma3:1b model downloaded.');
  }
} catch (error) {
  console.log('‚ùå Failed to check/download Ollama model:', error.message);
  process.exit(1);
}

console.log('\nüéâ Setup complete!');
console.log('\nNext steps:');
console.log('1. Update .env.local with your PostgreSQL credentials');
console.log('2. Run: npm run db:migrate');
console.log('3. Start Ollama: ollama serve');
console.log('4. Run the app: npm run dev');